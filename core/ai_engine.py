import streamlit as st
import google.generativeai as genai
from tenacity import retry, stop_after_attempt, wait_exponential

def setup_gemini(model_name):
    if "GOOGLE_API_KEY" not in st.secrets:
        raise ValueError("Thi·∫øu API Key")
    
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    
    # T·ª± ƒë·ªông g√°n "-latest" ƒë·ªÉ ch·ªëng l·ªói 404 Not Found c·ªßa Google
    if "-latest" not in model_name:
        model_name = f"{model_name}-latest"
        
    return genai.GenerativeModel(model_name)

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def ask_ai_primary(ticker, language, model_name, context=""):
    model = setup_gemini(model_name)

    base_prompt = f"""
    B·∫°n l√† Gi√°m ƒë·ªëc Ph√¢n t√≠ch Chi·∫øn l∆∞·ª£c. H√£y ph√¢n t√≠ch m√£/th·ªã tr∆∞·ªùng: {ticker}
    Ng√¥n ng·ªØ: {language}
    Y√äU C·∫¶U: ƒê√°nh gi√° ƒë·ªãnh gi√°, d√≤ng ti·ªÅn, vƒ© m√¥ v√† ƒë∆∞a ra khuy·∫øn ngh·ªã.
    """
    
    final_prompt = f"{base_prompt}\n\nNg∆∞·ªùi d√πng h·ªèi th√™m: {context}" if context else base_prompt
    
    response = model.generate_content(final_prompt)
    return f"**[ü§ñ CHUY√äN GIA AI]**\n\n{response.text}"

def get_ai_analysis(ticker, language="Ti·∫øng Vi·ªát", model_name="gemini-1.5-flash-latest", context=""):
    try:
        return ask_ai_primary(ticker, language, model_name, context)
    except Exception as e:
        error_msg = str(e)
        if "429" in error_msg or "Rate limited" in error_msg or "quota" in error_msg.lower():
            return "‚è≥ **Google b√°o AI ƒëang qu√° t·∫£i.** Vui l√≤ng ƒë·ª£i 1 ph√∫t r·ªìi nh·∫•n t√¨m ki·∫øm l·∫°i."
        elif "404" in error_msg:
            return f"‚ùå **L·ªói Google AI:** Kh√¥ng t√¨m th·∫•y model {model_name}. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh."
        else:
            return f"‚ö†Ô∏è **L·ªói AI:** {error_msg}"
