import streamlit as st
import google.generativeai as genai
from tenacity import retry, stop_after_attempt, wait_exponential

# ==========================================
# C·∫§U H√åNH K·∫æT N·ªêI GEMINI
# ==========================================
def setup_gemini(model_name):
    try:
        # L·∫•y ch√¨a kh√≥a t·ª´ "k√©t s·∫Øt" Secrets c·ªßa Streamlit
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        # Kh·ªüi t·∫°o model d·ª±a tr√™n l·ª±a ch·ªçn c·ªßa ng∆∞·ªùi d√πng
        model = genai.GenerativeModel(model_name)
        return model
    except Exception as e:
        st.error(f"L·ªói c·∫•u h√¨nh API Gemini: {e}")
        return None

# ==========================================
# C∆† CH·∫æ 1: G·ªåI MODEL AI CH√çNH (LINH HO·∫†T MODEL)
# ==========================================
@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def ask_ai_primary(ticker, language, model_name):
    model = setup_gemini(model_name)
    if not model:
        raise Exception("Kh√¥ng th·ªÉ k·∫øt n·ªëi Gemini")

    # System Prompt chuy√™n gia t√†i ch√≠nh
    prompt = f"""
    B·∫°n l√† m·ªôt Gi√°m ƒë·ªëc Ph√¢n t√≠ch Chi·∫øn l∆∞·ª£c t·∫°i m·ªôt qu·ªπ ƒë·∫ßu t∆∞ l·ªõn.
    H√£y ph√¢n t√≠ch m√£ c·ªï phi·∫øu: {ticker}
    Ng√¥n ng·ªØ tr·∫£ l·ªùi: {language}
    Model ƒëang s·ª≠ d·ª•ng: {model_name}
    
    Y√äU C·∫¶U PH√ÇN T√çCH:
    1. **ƒê·ªãnh gi√°:** D·ª±a v√†o ch·ªâ s·ªë P/E v√† P/B, h√£y ƒë√°nh gi√° m√£ n√†y ƒëang ƒê·∫Øt hay R·∫ª so v·ªõi trung b√¨nh ng√†nh.
    2. **D√≤ng ti·ªÅn & K·ªπ thu·∫≠t:** Nh·∫≠n ƒë·ªãnh v·ªÅ bi·∫øn ƒë·ªông kh·ªëi l∆∞·ª£ng (Volume) v√† c√°c ng∆∞·ª°ng h·ªó tr·ª£/kh√°ng c·ª±.
    3. **Vƒ© m√¥:** Nh·ªØng y·∫øu t·ªë vƒ© m√¥ hi·ªán t·∫°i ·∫£nh h∆∞·ªüng th·∫ø n√†o ƒë·∫øn doanh nghi·ªáp n√†y?
    4. **Khuy·∫øn ngh·ªã:** H√†nh ƒë·ªông c·ª• th·ªÉ (Mua/B√°n/Theo d√µi) v√† gi√° m·ª•c ti√™u d·ª± ki·∫øn.

    PHONG C√ÅCH: Chuy√™n nghi·ªáp, s√∫c t√≠ch, tr√¨nh b√†y Markdown ƒë·∫πp m·∫Øt v·ªõi c√°c icon.
    """
    
    response = model.generate_content(prompt)
    return f"**[ü§ñ CHUY√äN GIA AI - {model_name.upper()}]**\n\n{response.text}"

# ==========================================
# C∆† CH·∫æ 2 & 3: D·ª∞ PH√íNG & ƒêI·ªÄU PH·ªêI
# ==========================================
def ask_ai_fallback(ticker, language):
    if language == "Ti·∫øng Vi·ªát":
        return f"‚ö†Ô∏è *H·ªá th·ªëng AI ƒëang b·∫≠n ho·∫∑c l·ªói c·∫•u h√¨nh. M√£ **{ticker}** hi·ªán ƒëang ·ªü v√πng theo d√µi. Vui l√≤ng ki·ªÉm tra API Key.*"
    else:
        return f"‚ö†Ô∏è *AI System busy. Ticker **{ticker}** is under observation. Check API Key.*"

def get_ai_analysis(ticker, language="Ti·∫øng Vi·ªát", model_name="gemini-1.5-flash"):
    """
    H√†m nh·∫≠n th√™m tham s·ªë model_name ƒë·ªÉ linh ho·∫°t theo ng∆∞·ªùi d√πng.
    """
    try:
        return ask_ai_primary(ticker, language, model_name)
    except Exception as e:
        print(f"L·ªói AI ({model_name}): {e}")
        return ask_ai_fallback(ticker, language)
